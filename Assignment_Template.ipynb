{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin Number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Overview (provide your video link here too)\n",
    "\n",
    "**Problem:** Predict whether a student will complete an online course based on demographic, behavioural, and engagement features.\n",
    "\n",
    "**Dataset:** [Student Course Completion Prediction Dataset](https://www.kaggle.com/datasets/nisargpatel344/student-course-completion-prediction-dataset) — 100,000 records with 40 features covering student demographics, course details, learning behaviour, and payment information.\n",
    "\n",
    "**Approach:** This is a binary classification problem (Completed vs Not Completed). We train and compare Logistic Regression, Random Forest, and Gradient Boosting classifiers, then tune the best performer using GridSearchCV and validate with Stratified K-Fold Cross-Validation.\n",
    "\n",
    "**Video link:** *(insert link here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "\n",
    "1. [Import libraries](#imports)\n",
    "2. [Import data](#import_data)\n",
    "3. [Data exploration](#data_exploration)\n",
    "4. [Data cleaning and preparation](#data_cleaning)\n",
    "5. [Model training](#model_training)<br>\n",
    "6. [Model comparison](#model_comparsion)<br>\n",
    "7. [Tuning](#tuning)<br>\n",
    "8. [Validation](#validation)<br>\n",
    "9. [Conclusion](#conclusion)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries <a id='imports'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:46.334212Z",
     "iopub.status.busy": "2026-02-15T08:45:46.333963Z",
     "iopub.status.idle": "2026-02-15T08:45:47.662929Z",
     "shell.execute_reply": "2026-02-15T08:45:47.661965Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, StratifiedKFold,\n",
    "                                     cross_val_score, StratifiedShuffleSplit)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix, roc_auc_score, roc_curve)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import data <a id='import_data'></a>\n",
    "[Back to top](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:47.695120Z",
     "iopub.status.busy": "2026-02-15T08:45:47.694812Z",
     "iopub.status.idle": "2026-02-15T08:45:47.991653Z",
     "shell.execute_reply": "2026-02-15T08:45:47.990809Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Course_Completion_Prediction.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:47.993199Z",
     "iopub.status.busy": "2026-02-15T08:45:47.993011Z",
     "iopub.status.idle": "2026-02-15T08:45:47.996906Z",
     "shell.execute_reply": "2026-02-15T08:45:47.996233Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Column names and data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data exploration <a id='data_exploration'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "In this section we perform Exploratory Data Analysis (EDA) to understand the structure, distributions, and relationships within the data before modelling.\n",
    "\n",
    "**Dataset-Specific Constraint:** The dataset is pre-cleaned with **no missing values** and a **nearly balanced target** (~49% Completed vs ~51% Not Completed). While balanced classes simplify classification, the absence of real-world data quality issues means we must **introduce dirty data** (missing values, duplicates) in the next section for learning purposes. Additionally, some features such as `Student_ID`, `Name`, `Enrollment_Date`, and `City` are identifiers or high-cardinality categorical variables that carry **no predictive signal** and must be removed to avoid model overfitting or data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:47.998515Z",
     "iopub.status.busy": "2026-02-15T08:45:47.998355Z",
     "iopub.status.idle": "2026-02-15T08:45:48.081484Z",
     "shell.execute_reply": "2026-02-15T08:45:48.080574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset summary statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:48.082986Z",
     "iopub.status.busy": "2026-02-15T08:45:48.082823Z",
     "iopub.status.idle": "2026-02-15T08:45:48.260453Z",
     "shell.execute_reply": "2026-02-15T08:45:48.259496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:48.262026Z",
     "iopub.status.busy": "2026-02-15T08:45:48.261862Z",
     "iopub.status.idle": "2026-02-15T08:45:48.404153Z",
     "shell.execute_reply": "2026-02-15T08:45:48.403383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['Completed'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df['Completed'].value_counts(normalize=True).round(4) * 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "df['Completed'].value_counts().plot(kind='bar', color=['#e74c3c', '#2ecc71'], ax=ax)\n",
    "ax.set_title('Distribution of Course Completion')\n",
    "ax.set_xlabel('Completion Status')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('target_distribution.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"The target classes are nearly balanced, so class imbalance is NOT a constraint here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:48.405781Z",
     "iopub.status.busy": "2026-02-15T08:45:48.405609Z",
     "iopub.status.idle": "2026-02-15T08:45:49.641524Z",
     "shell.execute_reply": "2026-02-15T08:45:49.640686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of key numerical features\n",
    "numerical_cols = ['Age', 'Login_Frequency', 'Average_Session_Duration_Min',\n",
    "                  'Video_Completion_Rate', 'Quiz_Score_Avg', 'Progress_Percentage',\n",
    "                  'Assignments_Submitted', 'Assignments_Missed', 'Satisfaction_Rating']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    df[col].hist(bins=30, ax=ax, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(col)\n",
    "plt.suptitle('Distribution of Key Numerical Features', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('numerical_distributions.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:49.643231Z",
     "iopub.status.busy": "2026-02-15T08:45:49.643041Z",
     "iopub.status.idle": "2026-02-15T08:45:50.175336Z",
     "shell.execute_reply": "2026-02-15T08:45:50.174461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap of numerical features\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.heatmap(numeric_df.corr(), annot=False, cmap='coolwarm', center=0, ax=ax)\n",
    "ax.set_title('Correlation Heatmap of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:50.176881Z",
     "iopub.status.busy": "2026-02-15T08:45:50.176709Z",
     "iopub.status.idle": "2026-02-15T08:45:50.914768Z",
     "shell.execute_reply": "2026-02-15T08:45:50.913946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Boxplots of key features by completion status\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "box_features = ['Video_Completion_Rate', 'Quiz_Score_Avg', 'Progress_Percentage',\n",
    "                'Login_Frequency', 'Assignments_Submitted', 'Satisfaction_Rating']\n",
    "for i, col in enumerate(box_features):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    df.boxplot(column=col, by='Completed', ax=ax)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('')\n",
    "plt.suptitle('Feature Distributions by Completion Status', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots_by_completion.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Key observation: Progress_Percentage and Video_Completion_Rate show clear separation between completed and not completed students.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:50.916304Z",
     "iopub.status.busy": "2026-02-15T08:45:50.916115Z",
     "iopub.status.idle": "2026-02-15T08:45:51.888857Z",
     "shell.execute_reply": "2026-02-15T08:45:51.888071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical feature distributions\n",
    "cat_features = ['Gender', 'Education_Level', 'Employment_Status', 'Device_Type',\n",
    "                'Internet_Connection_Quality', 'Course_Level', 'Category']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(cat_features):\n",
    "    ct = pd.crosstab(df[col], df['Completed'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', ax=axes[i], stacked=True, color=['#e74c3c', '#2ecc71'])\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_ylabel('Percentage')\n",
    "    axes[i].legend(title='', fontsize=8)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "if len(cat_features) < len(axes):\n",
    "    axes[-1].set_visible(False)\n",
    "plt.suptitle('Completion Rate by Categorical Features', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_completion_rates.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: Completion rates are relatively uniform across most categorical features,\")\n",
    "print(\"suggesting that behavioural/engagement features may be more predictive than demographics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Summary & Dataset Constraint Discussion\n",
    "\n",
    "**Key findings from EDA:**\n",
    "1. The dataset has 100,000 rows and 40 columns with **no missing values** — it is pre-cleaned.\n",
    "2. The target variable is **nearly balanced** (~49% Completed vs ~51% Not Completed).\n",
    "3. `Progress_Percentage`, `Video_Completion_Rate`, and `Quiz_Score_Avg` show the strongest visual separation between completed and not-completed students.\n",
    "4. Most categorical features (Gender, Education_Level, etc.) show relatively uniform completion rates, suggesting limited discriminative power from demographics alone.\n",
    "\n",
    "**Dataset-Specific Constraint (referenced throughout):**\n",
    "The dataset contains **high-cardinality identifier columns** (`Student_ID`, `Name`, `City`) and **date strings** (`Enrollment_Date`) that could cause overfitting if included as features. Additionally, the data is **entirely pre-cleaned**, which while convenient, means we must **artificially introduce data quality issues** to practise real-world data preprocessing skills. We address this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data cleaning and preparation <a id='data_cleaning'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "Since the dataset is pre-cleaned (no missing values), we will **introduce dirty data for learning purposes** as required by the assignment, then clean it. We also perform feature engineering and encoding.\n",
    "\n",
    "> **Decision Point 1 — Feature Encoding Strategy:**\n",
    "> - **Alternative considered:** One-Hot Encoding for all categorical features. This would create a very wide feature matrix (e.g., `City` alone has 15+ unique values), increasing dimensionality and training time without meaningful predictive benefit for tree-based models.\n",
    "> - **Final choice:** Label Encoding for ordinal features (`Education_Level`, `Course_Level`, `Internet_Connection_Quality`) and One-Hot Encoding only for low-cardinality nominal features (`Gender`, `Employment_Status`, `Device_Type`, `Category`, `Payment_Mode`). High-cardinality columns (`City`, `Course_Name`, `Course_ID`) are dropped.\n",
    "> - **Justification:** This hybrid approach keeps dimensionality manageable, respects ordinal relationships, and avoids the curse of dimensionality from one-hot encoding high-cardinality features. The dataset constraint of having **identifier-like columns** (`Student_ID`, `Name`) and **high-cardinality categoricals** (`City` with 15 values) directly influenced this decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:51.890521Z",
     "iopub.status.busy": "2026-02-15T08:45:51.890356Z",
     "iopub.status.idle": "2026-02-15T08:45:52.190400Z",
     "shell.execute_reply": "2026-02-15T08:45:52.189525Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 1: Introduce dirty data for learning purposes ---\n",
    "df_dirty = df.copy()\n",
    "\n",
    "# Introduce ~2% missing values in selected columns\n",
    "np.random.seed(42)\n",
    "for col in ['Age', 'Video_Completion_Rate', 'Quiz_Score_Avg', 'Satisfaction_Rating']:\n",
    "    mask = np.random.random(len(df_dirty)) < 0.02\n",
    "    df_dirty.loc[mask, col] = np.nan\n",
    "\n",
    "# Introduce ~500 duplicate rows\n",
    "dup_indices = np.random.choice(df_dirty.index, size=500, replace=False)\n",
    "duplicates = df_dirty.loc[dup_indices].copy()\n",
    "df_dirty = pd.concat([df_dirty, duplicates], ignore_index=True)\n",
    "\n",
    "print(f\"Dirty dataset shape: {df_dirty.shape}\")\n",
    "print(f\"\\nMissing values introduced:\")\n",
    "print(df_dirty.isnull().sum()[df_dirty.isnull().sum() > 0])\n",
    "print(f\"\\nDuplicate rows: {df_dirty.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.191873Z",
     "iopub.status.busy": "2026-02-15T08:45:52.191706Z",
     "iopub.status.idle": "2026-02-15T08:45:52.421647Z",
     "shell.execute_reply": "2026-02-15T08:45:52.420912Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 2: Clean the dirty data ---\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df_dirty.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"After removing duplicates: {df_clean.shape}\")\n",
    "\n",
    "# Fill missing values with median (numerical)\n",
    "for col in ['Age', 'Video_Completion_Rate', 'Quiz_Score_Avg', 'Satisfaction_Rating']:\n",
    "    median_val = df_clean[col].median()\n",
    "    df_clean[col] = df_clean[col].fillna(median_val)\n",
    "    print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "\n",
    "print(f\"\\nRemaining missing values: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.423273Z",
     "iopub.status.busy": "2026-02-15T08:45:52.423079Z",
     "iopub.status.idle": "2026-02-15T08:45:52.428032Z",
     "shell.execute_reply": "2026-02-15T08:45:52.427346Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 3: Drop identifier and non-predictive columns ---\n",
    "\n",
    "# These columns are identifiers or have too high cardinality to be useful\n",
    "drop_cols = ['Student_ID', 'Name', 'Enrollment_Date', 'City', 'Course_ID', 'Course_Name']\n",
    "df_clean = df_clean.drop(columns=drop_cols)\n",
    "print(f\"Dropped columns: {drop_cols}\")\n",
    "print(f\"Remaining columns: {df_clean.shape[1]}\")\n",
    "print(f\"Columns: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.429573Z",
     "iopub.status.busy": "2026-02-15T08:45:52.429408Z",
     "iopub.status.idle": "2026-02-15T08:45:52.436655Z",
     "shell.execute_reply": "2026-02-15T08:45:52.436016Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 4: Encode the target variable ---\n",
    "df_clean['Completed'] = df_clean['Completed'].map({'Completed': 1, 'Not Completed': 0})\n",
    "print(\"Target encoding: Completed=1, Not Completed=0\")\n",
    "print(df_clean['Completed'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.438394Z",
     "iopub.status.busy": "2026-02-15T08:45:52.438218Z",
     "iopub.status.idle": "2026-02-15T08:45:52.512896Z",
     "shell.execute_reply": "2026-02-15T08:45:52.511903Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 5: Encode categorical features ---\n",
    "\n",
    "# Ordinal encoding for features with natural order\n",
    "ordinal_maps = {\n",
    "    'Education_Level': {'HighSchool': 0, 'Diploma': 1, 'Bachelor': 2, 'Master': 3, 'PhD': 4},\n",
    "    'Course_Level': {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2},\n",
    "    'Internet_Connection_Quality': {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_maps.items():\n",
    "    df_clean[col] = df_clean[col].map(mapping)\n",
    "    print(f\"Ordinal encoded {col}: {mapping}\")\n",
    "\n",
    "# One-hot encoding for nominal features\n",
    "nominal_cols = ['Gender', 'Employment_Status', 'Device_Type', 'Category', 'Payment_Mode', 'Fee_Paid', 'Discount_Used']\n",
    "df_clean = pd.get_dummies(df_clean, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(f\"\\nFinal dataset shape after encoding: {df_clean.shape}\")\n",
    "print(f\"\\nFeature columns: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.514379Z",
     "iopub.status.busy": "2026-02-15T08:45:52.514214Z",
     "iopub.status.idle": "2026-02-15T08:45:52.519233Z",
     "shell.execute_reply": "2026-02-15T08:45:52.518537Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 6: Feature Engineering ---\n",
    "\n",
    "# Create engagement ratio: assignments submitted vs total assignments\n",
    "df_clean['Assignment_Completion_Rate'] = df_clean['Assignments_Submitted'] / (\n",
    "    df_clean['Assignments_Submitted'] + df_clean['Assignments_Missed'] + 1e-9)\n",
    "\n",
    "# Create a combined quiz performance metric\n",
    "df_clean['Quiz_Performance'] = df_clean['Quiz_Score_Avg'] * df_clean['Quiz_Attempts']\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "print(\"  - Assignment_Completion_Rate: ratio of submitted to total assignments\")\n",
    "print(\"  - Quiz_Performance: quiz score weighted by number of attempts\")\n",
    "print(f\"\\nFinal dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.520912Z",
     "iopub.status.busy": "2026-02-15T08:45:52.520753Z",
     "iopub.status.idle": "2026-02-15T08:45:52.589941Z",
     "shell.execute_reply": "2026-02-15T08:45:52.589162Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 7: Prepare features and target, split data ---\n",
    "X = df_clean.drop('Completed', axis=1)\n",
    "y = df_clean['Completed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts(normalize=True).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.591440Z",
     "iopub.status.busy": "2026-02-15T08:45:52.591274Z",
     "iopub.status.idle": "2026-02-15T08:45:52.632889Z",
     "shell.execute_reply": "2026-02-15T08:45:52.632206Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 8: Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled using StandardScaler.\")\n",
    "print(f\"Scaled training set shape: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model training <a id='model_training'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "We train three classification models:\n",
    "1. **Logistic Regression** — A simple linear baseline.\n",
    "2. **Random Forest** — An ensemble of decision trees (handles non-linear relationships well).\n",
    "3. **Gradient Boosting** — A sequential ensemble method (often achieves higher accuracy).\n",
    "\n",
    "> **Decision Point 2 — Model Selection:**\n",
    "> - **Alternative considered:** Support Vector Machine (SVM). SVM can achieve strong classification performance, especially with kernel tricks. However, SVM scales poorly with large datasets — training time is approximately O(n² × features), making it impractical for our **100,000-row dataset** without significant subsampling, which would reduce representativeness.\n",
    "> - **Final choice:** Logistic Regression, Random Forest, and Gradient Boosting.\n",
    "> - **Justification:** Logistic Regression provides an interpretable linear baseline. Random Forest and Gradient Boosting are both scalable ensemble methods that handle mixed feature types well and train efficiently on large datasets. The **dataset-specific constraint** of having 100,000 rows makes SVM computationally expensive, so tree-based ensembles are a better fit. Additionally, the nearly balanced class distribution means we do not need specialised techniques like SMOTE or class weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:52.634588Z",
     "iopub.status.busy": "2026-02-15T08:45:52.634418Z",
     "iopub.status.idle": "2026-02-15T08:45:53.217458Z",
     "shell.execute_reply": "2026-02-15T08:45:53.215241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_prob = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression trained.\")\n",
    "print(f\"Training accuracy: {lr_model.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, lr_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:53.219415Z",
     "iopub.status.busy": "2026-02-15T08:45:53.219056Z",
     "iopub.status.idle": "2026-02-15T08:45:59.924858Z",
     "shell.execute_reply": "2026-02-15T08:45:59.923944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model 2: Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest trained.\")\n",
    "print(f\"Training accuracy: {rf_model.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, rf_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:45:59.926414Z",
     "iopub.status.busy": "2026-02-15T08:45:59.926248Z",
     "iopub.status.idle": "2026-02-15T08:46:44.034255Z",
     "shell.execute_reply": "2026-02-15T08:46:44.033519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model 3: Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "gb_prob = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Gradient Boosting trained.\")\n",
    "print(f\"Training accuracy: {gb_model.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, gb_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model comparison <a id='model_comparsion'></a>\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "We compare all three models using Accuracy, Precision, Recall, F1-Score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:46:44.035905Z",
     "iopub.status.busy": "2026-02-15T08:46:44.035735Z",
     "iopub.status.idle": "2026-02-15T08:46:44.078430Z",
     "shell.execute_reply": "2026-02-15T08:46:44.077588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "models = {\n",
    "    'Logistic Regression': (lr_pred, lr_prob),\n",
    "    'Random Forest': (rf_pred, rf_prob),\n",
    "    'Gradient Boosting': (gb_pred, gb_prob)\n",
    "}\n",
    "\n",
    "for name, (pred, prob) in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name}\")\n",
    "    print('='*50)\n",
    "    print(classification_report(y_test, pred, target_names=['Not Completed', 'Completed']))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, prob):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:46:44.079942Z",
     "iopub.status.busy": "2026-02-15T08:46:44.079776Z",
     "iopub.status.idle": "2026-02-15T08:46:44.124538Z",
     "shell.execute_reply": "2026-02-15T08:46:44.123725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "results = []\n",
    "for name, (pred, prob) in models.items():\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, pred),\n",
    "        'Precision': precision_score(y_test, pred),\n",
    "        'Recall': recall_score(y_test, pred),\n",
    "        'F1-Score': f1_score(y_test, pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, prob)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:46:44.126229Z",
     "iopub.status.busy": "2026-02-15T08:46:44.126028Z",
     "iopub.status.idle": "2026-02-15T08:46:44.562807Z",
     "shell.execute_reply": "2026-02-15T08:46:44.561935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, (name, (pred, _)) in enumerate(models.items()):\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Not Completed', 'Completed'],\n",
    "                yticklabels=['Not Completed', 'Completed'])\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_ylabel('Actual')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "plt.suptitle('Confusion Matrices', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:46:44.564648Z",
     "iopub.status.busy": "2026-02-15T08:46:44.564464Z",
     "iopub.status.idle": "2026-02-15T08:46:44.769601Z",
     "shell.execute_reply": "2026-02-15T08:46:44.768764Z"
    }
   },
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for name, (_, prob) in models.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, prob)\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    ax.plot(fpr, tpr, label=f'{name} (AUC={auc:.4f})')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:46:44.771294Z",
     "iopub.status.busy": "2026-02-15T08:46:44.771093Z",
     "iopub.status.idle": "2026-02-15T08:46:44.992819Z",
     "shell.execute_reply": "2026-02-15T08:46:44.991995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance (Random Forest)\n",
    "feature_importance = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "top_features = feature_importance.nlargest(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_features.sort_values().plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_title('Top 15 Feature Importances (Random Forest)')\n",
    "ax.set_xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 most important features:\")\n",
    "for feat, imp in top_features.head(5).items():\n",
    "    print(f\"  {feat}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Summary\n",
    "\n",
    "Based on the comparison above, we select the best-performing model for hyperparameter tuning in the next section. The comparison considers all metrics — Accuracy, Precision, Recall, F1, and AUC — with particular attention to F1-Score as a balanced metric.\n",
    "\n",
    "**Dataset constraint reference:** Since the target classes are nearly balanced, accuracy is a reliable metric here. If the classes were imbalanced, we would need to rely more heavily on Precision, Recall, and F1-Score to avoid being misled by accuracy alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tuning <a id='tuning'></a>\n",
    "\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "We perform hyperparameter tuning on the Gradient Boosting model using GridSearchCV, as it typically offers the best trade-off between performance and interpretability in our comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:46:44.994445Z",
     "iopub.status.busy": "2026-02-15T08:46:44.994263Z",
     "iopub.status.idle": "2026-02-15T08:47:24.395191Z",
     "shell.execute_reply": "2026-02-15T08:47:24.394477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Gradient Boosting using GridSearchCV\n",
    "# Use a stratified subsample for tuning to keep computation tractable\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.85, random_state=42)\n",
    "tune_idx, _ = next(sss.split(X_train, y_train))\n",
    "X_tune, y_tune = X_train.iloc[tune_idx], y_train.iloc[tune_idx]\n",
    "print(f\"Tuning subsample size: {X_tune.shape[0]} (15% of training data)\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_tune, y_tune)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV F1-Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:47:24.396998Z",
     "iopub.status.busy": "2026-02-15T08:47:24.396835Z",
     "iopub.status.idle": "2026-02-15T08:47:50.827277Z",
     "shell.execute_reply": "2026-02-15T08:47:50.826490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrain best model on full training data with tuned hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = GradientBoostingClassifier(random_state=42, **best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "tuned_pred = best_model.predict(X_test)\n",
    "tuned_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Tuned Gradient Boosting - Test Set Performance:\")\n",
    "print(classification_report(y_test, tuned_pred, target_names=['Not Completed', 'Completed']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, tuned_prob):.4f}\")\n",
    "\n",
    "# Compare before and after tuning\n",
    "print(f\"\\nBefore tuning - Accuracy: {accuracy_score(y_test, gb_pred):.4f}, F1: {f1_score(y_test, gb_pred):.4f}\")\n",
    "print(f\"After tuning  - Accuracy: {accuracy_score(y_test, tuned_pred):.4f}, F1: {f1_score(y_test, tuned_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Validation <a id='validation'></a>\n",
    "\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "We apply Stratified K-Fold Cross-Validation to assess model generalisation. Stratified K-Fold ensures each fold preserves the class distribution, which is important for reliable performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:47:50.828945Z",
     "iopub.status.busy": "2026-02-15T08:47:50.828767Z",
     "iopub.status.idle": "2026-02-15T08:48:36.802376Z",
     "shell.execute_reply": "2026-02-15T08:48:36.801459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stratified K-Fold Cross-Validation on the tuned model\n",
    "# Use a representative subsample for cross-validation to keep computation tractable\n",
    "sss_cv = StratifiedShuffleSplit(n_splits=1, test_size=0.8, random_state=42)\n",
    "cv_idx, _ = next(sss_cv.split(X, y))\n",
    "X_cv, y_cv = X.iloc[cv_idx], y.iloc[cv_idx]\n",
    "print(f\"Cross-validation subsample size: {X_cv.shape[0]}\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracy = cross_val_score(best_model, X_cv, y_cv, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "cv_f1 = cross_val_score(best_model, X_cv, y_cv, cv=skf, scoring='f1', n_jobs=-1)\n",
    "cv_precision = cross_val_score(best_model, X_cv, y_cv, cv=skf, scoring='precision', n_jobs=-1)\n",
    "cv_recall = cross_val_score(best_model, X_cv, y_cv, cv=skf, scoring='recall', n_jobs=-1)\n",
    "\n",
    "print(\"5-Fold Stratified Cross-Validation Results (Tuned Gradient Boosting):\")\n",
    "print(f\"  Accuracy:  {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std():.4f})\")\n",
    "print(f\"  F1-Score:  {cv_f1.mean():.4f} (+/- {cv_f1.std():.4f})\")\n",
    "print(f\"  Precision: {cv_precision.mean():.4f} (+/- {cv_precision.std():.4f})\")\n",
    "print(f\"  Recall:    {cv_recall.mean():.4f} (+/- {cv_recall.std():.4f})\")\n",
    "print(f\"\\nIndividual fold accuracies: {[round(x, 4) for x in cv_accuracy]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T08:48:36.803948Z",
     "iopub.status.busy": "2026-02-15T08:48:36.803769Z",
     "iopub.status.idle": "2026-02-15T08:48:36.930027Z",
     "shell.execute_reply": "2026-02-15T08:48:36.929147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise cross-validation results\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "means = [cv_accuracy.mean(), cv_f1.mean(), cv_precision.mean(), cv_recall.mean()]\n",
    "stds = [cv_accuracy.std(), cv_f1.std(), cv_precision.std(), cv_recall.std()]\n",
    "\n",
    "bars = ax.bar(metrics, means, yerr=stds, capsize=5, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'],\n",
    "              edgecolor='black', alpha=0.8)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('5-Fold Stratified Cross-Validation Results (Tuned Gradient Boosting)')\n",
    "\n",
    "for bar, mean in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{mean:.4f}',\n",
    "            ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_results.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Low standard deviation across folds indicates the model generalises well and is not overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusion <a id='conclusion'></a>\n",
    "\n",
    "[Back to top](#table_of_contents)\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "We built a binary classification pipeline to predict whether a student will complete an online course. Three models were trained and compared:\n",
    "\n",
    "| Step | What was done |\n",
    "|------|---------------|\n",
    "| Data Preprocessing | Introduced and cleaned dirty data (missing values, duplicates); dropped identifier columns; encoded categorical features |\n",
    "| EDA | Visualised distributions, correlations, and feature-target relationships |\n",
    "| Feature Engineering | Created `Assignment_Completion_Rate` and `Quiz_Performance` features |\n",
    "| Model Training | Trained Logistic Regression, Random Forest, and Gradient Boosting |\n",
    "| Model Comparison | Compared using Accuracy, Precision, Recall, F1-Score, and ROC-AUC |\n",
    "| Hyperparameter Tuning | GridSearchCV on Gradient Boosting with 3-fold CV |\n",
    "| Validation | 5-Fold Stratified Cross-Validation on tuned model |\n",
    "\n",
    "### Decision Points Recap\n",
    "\n",
    "**Decision Point 1 — Feature Encoding Strategy:**\n",
    "We chose a hybrid encoding approach (ordinal for ordered features, one-hot for low-cardinality nominal features, and dropping high-cardinality identifiers) instead of one-hot encoding everything. This was driven by the dataset constraint of having identifier-like columns and high-cardinality categoricals that would inflate dimensionality without improving predictions.\n",
    "\n",
    "**Decision Point 2 — Model Selection:**\n",
    "We chose Logistic Regression, Random Forest, and Gradient Boosting over SVM. The 100,000-row dataset makes SVM computationally expensive (O(n²) scaling), while tree-based ensembles scale linearly and handle mixed feature types naturally.\n",
    "\n",
    "### Dataset-Specific Constraint\n",
    "\n",
    "The primary constraint is that this dataset is **pre-cleaned with no missing values**, which is unrealistic for real-world data science. We addressed this by intentionally introducing dirty data to practise preprocessing skills. Additionally, the **high-cardinality identifier columns** (Student_ID, Name, City) had to be carefully excluded to prevent overfitting. The **near-balanced target distribution** (~49/51%) meant standard accuracy was a valid evaluation metric and specialised imbalance-handling techniques (SMOTE, class weighting) were unnecessary.\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "The tuned Gradient Boosting model provides robust predictions of course completion. Key predictive features (visible from feature importance analysis) can be used by course providers to identify at-risk students early and implement targeted interventions to improve completion rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
